## 서민수

### 데이터 전처리

- Req. 1-1 영화 댓글, 평점 데이터 전 처리 구현을 조원과 함께 학습했습니다.
- 개인적으로 구현한 코드 올립니다.

영화 댓글, 평점 데이터 전처리

```python
import numpy as np
import pickle

from konlpy.tag import Okt
from scipy.sparse import lil_matrix
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression

"""
Req 1-1-1. 데이터 읽기
read_data(): 데이터를 읽어서 저장하는 함수
"""

def read_data(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        data = [line.split('\t') for line in f.read().splitlines()]
        data = data[1:]   # header 제외
    return data
"""
Req 1-1-2. 토큰화 함수
tokenize(): 텍스트 데이터를 받아 KoNLPy의 okt 형태소 분석기로 토크나이징
"""
okt_tag = Okt()
def tokenize(text):
    return ['/'.join(t) for t in okt_tag.pos(text, norm=True, stem=True)]

"""
데이터 전 처리
"""

# train, test 데이터 읽기
train_data = read_data('ratings_train.txt')
test_data = read_data('ratings_test.txt')


# Req 1-1-2. 문장 데이터 토큰화
# train_docs, test_docs : 토큰화된 트레이닝, 테스트  문장에 label 정보를 추가한 list


train_docs = [(tokenize(row[1]), row[2]) for row in train_data[:20]]
test_docs = [(tokenize(row[1]), row[2]) for row in test_data[:20]]

# from pprint import pprint
# pprint(train_docs[0])
train_tokens = [t for d in train_docs for t in d[0]]
test_tokens = [t for d in test_docs for t in d[0]]
# print(len(tokens))
# Req 1-1-3. word_indices 초기화
word_indices = {}

# Req 1-1-3. word_indices 채우기
for d in train_docs:
    for vo in d[0]:
        if word_indices.get(vo)==None:
            word_indices[vo]=len(word_indices)
print(word_indices)

def one_hot_encoding(word, word2index):
       one_hot_vector = [0]*(len(word2index))
       index=word2index[word]
       one_hot_vector[index]=1
       return one_hot_vector

# Req 1-1-4. sparse matrix 초기화
# X: train feature data
# X_test: test feature data
X = np.zeros((len(train_docs), len(word_indices)))
X_test = np.zeros((len(test_docs), len(word_indices)))
print(X.shape)
print(X_test.shape)

# # 평점 label 데이터가 저장될 Y 행렬 초기화
# # Y: train data label
# # Y_test: test data label
Y = np.zeros((len(train_docs), 1))
Y_test = np.zeros((len(test_docs), 1))

# # Req 1-1-5. one-hot 임베딩
# # X,Y 벡터값 채우기

# for idx in range(len(test_docs)):
#     temp = [0]*len(word_indices)
#     for verb in test_docs[idx]:
#         part = verb.split('/')[0]
#         if word_indices.get(part)!=None:
#             temp[word_indices[part]]=1
#     X_test[idx]=temp

```

